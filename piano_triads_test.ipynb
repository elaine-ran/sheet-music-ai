{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78525ccd-765f-452c-9776-5345718674a1",
   "metadata": {},
   "source": [
    "dataset from: https://www.kaggle.com/datasets/davidbroberts/piano-triads-wavset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d5e2d2c-c85d-4577-9e95-34274966fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv1D, MaxPooling1D\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbd46e13-f473-42c3-b785-3750a4392c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/elaineran/Downloads/archive2/piano_triads/\"\n",
    "metadata_path = \"/Users/elaineran/Desktop/summer-project/triads_modified.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21425291-e074-4df0-b263-df3240c6b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chord_edit\n",
    "import random\n",
    "\n",
    "funcs = [chord_edit.time_stretch, chord_edit.add_noise, chord_edit.time_stretch_and_add_noise]\n",
    "i = 1\n",
    "while i <11:\n",
    "    rand = random.randint(0, 2)\n",
    "    funcs[rand](data_path, metadata_path, i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b94e1565-3cd8-4049-abd4-8397f770b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, metadata_path):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "\n",
    "    for index, row in metadata.iterrows():\n",
    "        file_path = os.path.join(data_path, f\"{row['Chord']}.wav\")\n",
    "\n",
    "\n",
    "        # Load the audio file and resample it\n",
    "        target_sr = 22050\n",
    "        audio, sample_rate = librosa.load(file_path, sr=target_sr)\n",
    "\n",
    "        # Check if the audio length is less than the default n_fft size\n",
    "        if len(audio) < 2048:\n",
    "            # Pad the audio file with zeros\n",
    "            audio = np.pad(audio, (0, 2048 - len(audio)), mode='constant')\n",
    "\n",
    "\n",
    "\n",
    "        # Extract MFCC features\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=target_sr, n_mfcc=40)\n",
    "        mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "\n",
    "        # Append features and labels\n",
    "        features.append(mfccs_scaled)\n",
    "        labels.append(row['Chord_modified'])\n",
    "\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab0f1791-9232-438e-8e40-6b06a3a360d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = load_data(data_path, metadata_path)\n",
    "\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "labels_onehot = to_categorical(labels_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f74587fc-dbd8-4ffe-8ec0-d2b16d7cd394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_onehot, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3586150f-69cb-4a87-8ae8-03f01be93a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], 1)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(128, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(le.classes_), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "291b7376-da75-4fa3-9bd3-7e51cba39bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0139aa8-1f48-468a-bf44-f4d61fbc7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c589a4f-81b6-4eb6-be85-3964101e1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, le, file_path):\n",
    "    audio, sample_rate = librosa.load(file_path, sr=22050)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=22050, n_mfcc=40)\n",
    "    mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
    "    features = mfccs_scaled.reshape(1, mfccs_scaled.shape[0], 1)\n",
    "    predicted_vector = model.predict(features)\n",
    "    predicted_class_index = np.argmax(predicted_vector, axis=-1)\n",
    "    return le.inverse_transform(predicted_class_index)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e769f3e-e535-4a33-ad10-f609336d73d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the initial weights\n",
    "initial_weights = model.get_weights()\n",
    "\n",
    "\n",
    "# Dictionary to store old predictions\n",
    "old_predictions = {}\n",
    "new_predictions = {}\n",
    "\n",
    "\n",
    "# List of test files and their true labels\n",
    "#test_files = [\n",
    "    #(\"/Users/elaineran/Downloads/archive/fold1/101415-3-0-2.wav\", \"Dog bark\"),\n",
    "    #(\"/Users/elaineran/Downloads/archive/fold1/101415-3-0-3.wav\", \"Dog bark\"),\n",
    "    #(\"/Users/elaineran/Downloads/archive/fold1/102305-6-0-0.wav\", \"Gun shots\"),\n",
    "    #(\"/Users/elaineran/Downloads/archive/fold1/103074-7-0-2.wav\", \"Jack hammer\"),\n",
    "    #(\"/Users/elaineran/Downloads/archive/fold1/103074-7-4-3.wav\", \"Jack hammer\")\n",
    "#]\n",
    "\n",
    "\n",
    "# Make predictions before training\n",
    "#for file_path, true_label in test_files:\n",
    "    #predicted_label_before = make_predictions(model, le, file_path)\n",
    "    #old_predictions[file_path] = predicted_label_before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34140ed-9fbd-426a-a992-05f1996a4fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3168 samples, validate on 792 samples\n",
      "Epoch 1/100\n",
      "3168/3168 [==============================] - 5s 2ms/step - loss: 5.6763 - accuracy: 0.0319 - val_loss: 3.5490 - val_accuracy: 0.0707\n",
      "Epoch 2/100\n",
      "3168/3168 [==============================] - 4s 1ms/step - loss: 3.5616 - accuracy: 0.0496 - val_loss: 3.4005 - val_accuracy: 0.0821\n",
      "Epoch 3/100\n",
      "3168/3168 [==============================] - 5s 1ms/step - loss: 3.3373 - accuracy: 0.0922 - val_loss: 2.8614 - val_accuracy: 0.2247\n",
      "Epoch 4/100\n",
      "3168/3168 [==============================] - 4s 1ms/step - loss: 2.8264 - accuracy: 0.2030 - val_loss: 2.1813 - val_accuracy: 0.4192\n",
      "Epoch 5/100\n",
      "3168/3168 [==============================] - 4s 1ms/step - loss: 2.3655 - accuracy: 0.3242 - val_loss: 1.7457 - val_accuracy: 0.5556\n",
      "Epoch 6/100\n",
      "3168/3168 [==============================] - 5s 1ms/step - loss: 1.9485 - accuracy: 0.4410 - val_loss: 1.3811 - val_accuracy: 0.6427\n",
      "Epoch 7/100\n",
      "3168/3168 [==============================] - 5s 2ms/step - loss: 1.6039 - accuracy: 0.5319 - val_loss: 1.0760 - val_accuracy: 0.7311\n",
      "Epoch 8/100\n",
      "3168/3168 [==============================] - 4s 1ms/step - loss: 1.3357 - accuracy: 0.6102 - val_loss: 0.8341 - val_accuracy: 0.7992\n",
      "Epoch 9/100\n",
      "3168/3168 [==============================] - 4s 1ms/step - loss: 1.1422 - accuracy: 0.6679 - val_loss: 0.6506 - val_accuracy: 0.8497\n",
      "Epoch 10/100\n",
      "3168/3168 [==============================] - 4s 1ms/step - loss: 0.9010 - accuracy: 0.7165 - val_loss: 0.4380 - val_accuracy: 0.9167\n",
      "Epoch 11/100\n",
      "3168/3168 [==============================] - 5s 1ms/step - loss: 0.7333 - accuracy: 0.7661 - val_loss: 0.2643 - val_accuracy: 0.9495\n",
      "Epoch 12/100\n",
      "3168/3168 [==============================] - 5s 1ms/step - loss: 0.6185 - accuracy: 0.8071 - val_loss: 0.1870 - val_accuracy: 0.9672\n",
      "Epoch 13/100\n",
      "  32/3168 [..............................] - ETA: 4s - loss: 0.6279 - accuracy: 0.8438"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b89742-c1b7-4730-8c90-83f7a00f3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting from history\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = list(range(len(loss)))\n",
    "\n",
    "figsize = (6, 4)\n",
    "fig, axis1 = plt.subplots(figsize=figsize)\n",
    "plot1_lacc = axis1.plot(epochs, acc, 'navy', label='accuracy')\n",
    "plot1_val_lacc = axis1.plot(epochs, val_acc, 'deepskyblue', label=\"validation accuracy\")\n",
    "\n",
    "plot1_loss = axis1.plot(epochs, loss, 'red', label='loss')\n",
    "plot1_val_loss = axis1.plot(epochs, val_loss, 'lightsalmon', label=\"validation loss\")\n",
    "\n",
    "\n",
    "plots = plot1_loss + plot1_val_loss\n",
    "labs = [plot.get_label() for plot in plots]\n",
    "axis1.set_xlabel('Epoch')\n",
    "axis1.set_ylabel('Loss/Accuracy')\n",
    "plt.title(\"Loss/Accuracy History\")\n",
    "plt.tight_layout()\n",
    "axis1.legend(loc='lower right')\n",
    "plt.savefig(\"/Users/elaineran/Desktop/summer-project/figures/Loss-Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb885b8-f2d5-4e19-a085-0967fbe0f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfd603-b3d6-47fe-abc7-b19027a141d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices = np.argmax(test_predictions, axis=1)\n",
    "predicted_classes = le.inverse_transform(predicted_class_indices)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dc1555-b1df-484f-8c5b-1b647d1717da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "true_classes = le.inverse_transform(y_true)\n",
    "print(true_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7263ca4-19b2-4a8e-b954-e1fa51a956e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(np.concatenate([y_true, predicted_class_indices]))\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, predicted_class_indices)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Generate a classification report\n",
    "print(classification_report(y_true, predicted_class_indices, labels=unique_labels, target_names=le.inverse_transform(unique_labels)))\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, predicted_class_indices)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa54b0-bd8c-4048-ac42-42c314e80197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(\"/Users/elaineran/Desktop/summer-project/figures/Confusion-Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc32aff-38d0-44b1-9b21-3f36586962dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sbi_env)",
   "language": "python",
   "name": "sbi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
